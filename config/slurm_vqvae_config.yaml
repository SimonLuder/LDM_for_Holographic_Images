name: 'vqvae_8_512'

dataset: # Dataset configuration
  root: "data/"                                                 # root folder of the dataset
  img_channels : 1                                              # grayscale images
  img_size : 200                                                # original image size
  img_interpolation : 256                                       # size after interpolation or "Null"                   
  labels_train : data/final/poleno/basic_train.csv              # training labels
  labels_val : data/final/poleno/basic_val_20.csv               # validation labels
  labels_test : data/final/poleno/basic_test.csv                # test labels
  filenames : rec_path                                          # column name containing filenames
  img_path : img_path                                           # column name containing absolute or relative image path from root

autoencoder: # VQ-VAE architecture
  z_channels : 8                                                # latent dimension    
  codebook_size : 512                                           # number of distinct codebook vectors
  down_channels : [64, 128, 256, 256]                           # channels in each downsampling blocks
  mid_channels : [256, 256]                                     # channels in the middle blocks 
  down_sample : [True, True, True]                              # whether to downsample at each block  
  attns : [False, False, False]                                 # whether to use attention at each block
  norm_channels: 32                                             # number of channels for normalization
  num_heads : 4                                                 # number of attention heads
  num_down_layers : 2                                           # number of resnet layers in each downsampling block
  num_mid_layers : 2                                            # number of resnet layers in the middle block
  num_up_layers : 2                                             # number of resnet layers in each upsampling block

vqvae_train : # VQ-VAE training parameters
  seed: 42
  # task_name : 'holographic_pollen'
  ckpt_folder : 'checkpoints'
  autoencoder_lr: 0.00005
  autoencoder_epochs : 5
  autoencoder_batch_size : 8
  autoencoder_steps_per_optimization : 8
  autoencoder_img_save_steps : 10000
  autoencoder_ckpt_steps : 10000
  autoencoder_val_steps : 10000
  autoencoder_val_start : 10000
  codebook_weight : 1
  commitment_beta : 0.25 # https://arxiv.org/pdf/1711.00937.pdf
  perceptual_weight: 1 
  discriminator_start_step : 6000 # Set t step when VAE no longer improves with mse and lpips
  discriminator_loss : BCEWithLogits
  discriminator_weight : 0.5

vqvae_test :
  save_images : True
  model_ckpt : 'latest.pth'

vqvae_inference :
  save_images : True
  num_samples : 8
  num_grid_rows : 8
  upscale_latent_dim : True
  model_ckpt : 'latest.pth'

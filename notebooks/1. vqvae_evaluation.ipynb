{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceac26bd",
   "metadata": {},
   "source": [
    "# VQ-VAE Evaluation Notebook\n",
    "\n",
    "\n",
    "This notebook contains the evaluation of the trained VQ-VAE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78197844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26097155",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf8cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\n",
    "    'val_epoch_codebook_loss',\n",
    "    'val_epoch_reconstructon_loss',\n",
    "    'val_epoch_lpips_loss',\n",
    "]\n",
    "\n",
    "metric_names = [\n",
    "    'Codebook loss',\n",
    "    'Reconstructon loss',\n",
    "    'LPIPS loss',\n",
    "]\n",
    "\n",
    "api = wandb.Api(timeout=60)\n",
    "\n",
    "run = api.run(\"simonluder/MSE_P9_LDM/uedmx2jh\")\n",
    "\n",
    "history = run.history(keys=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da32b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [metric for metric in run.summary.keys() if \"val_\" in metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39898d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharex=True)\n",
    "\n",
    "for ax, key, name in zip(axes, keys, metric_names):\n",
    "    ax.plot(history[\"_step\"], history[key])\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.suptitle(\"Validation losses\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fbf13e",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7880011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic_test = pd.read_csv(r\"Z:\\simon_luder\\Data_Setup\\Pollen_Datasets\\data\\final\\poleno\\basic_test.csv\")\n",
    "df_isolated_all = pd.read_csv(r\"Z:\\simon_luder\\Data_Setup\\Pollen_Datasets\\data\\final\\poleno\\isolated_all.csv\")\n",
    "print(len(df_basic_test), len(df_isolated_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c72d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_basic_test = r\"C:\\Users\\simon\\Documents\\GitHub\\LDM_for_Holographic_Images\\checkpoints\\vqvae_8_512\\test\\basic_test_20251215_181623\\test_logs.json\"\n",
    "scores_isolated_all = r\"C:\\Users\\simon\\Documents\\GitHub\\LDM_for_Holographic_Images\\checkpoints\\vqvae_8_512\\test\\isolated_all_20251216_123210\\test_logs.json\"\n",
    "\n",
    "scores_basic_test = pd.read_json(scores_basic_test)\n",
    "scores_isolated_all = pd.read_json(scores_isolated_all)\n",
    "\n",
    "df_basic_test = pd.merge(df_basic_test, scores_basic_test, how=\"inner\", left_on=\"rec_path\", right_on=\"filenames\")\n",
    "df_isolated_all = pd.merge(df_isolated_all, scores_isolated_all, how=\"inner\", left_on=\"rec_path\", right_on=\"filenames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic_test[\"group\"] = \"seen\"\n",
    "df_isolated_all[\"group\"] = \"unseen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9802f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns = [\"test_reconstructon_loss\", \"test_codebook_loss\", \"test_lpips_loss\"]\n",
    "\n",
    "df = pd.concat([df_basic_test, df_isolated_all]).reset_index()\n",
    "# df = df.groupby([\"dataset_id\", \"group\"])[test_columns].mean().reset_index()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "metric = \"test_reconstruction_loss\"\n",
    "x = \"species\"\n",
    "\n",
    "order = df.groupby(x)[metric].median().sort_values().index\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "sns.boxplot(df, x=x, y=metric, hue=\"group\", fill=False, flierprops={\"marker\": \".\"}, fliersize=1, order=order)\n",
    "# plt.ylim(0, 0.002)\n",
    "plt.title(\"Test reconstruction loss per species\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad33ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"unseen\"\n",
    "sample = df.loc[df[\"group\"] == category]\n",
    "rest = df.loc[df[\"group\"] != category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ebbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perm_test_large_imbalance(species, others, *, stat=\"logmean\", alternative=\"two-sided\",\n",
    "                             n_perm=100000, eps=1e-12, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    species = np.asarray(species, dtype=float)\n",
    "    others  = np.asarray(others,  dtype=float)\n",
    "\n",
    "    pooled = np.concatenate([species, others])\n",
    "    nA = len(species)\n",
    "    N = len(pooled)\n",
    "\n",
    "    print(len(species),len(others),len(pooled))\n",
    "\n",
    "    # statistic\n",
    "    def transform(x):\n",
    "        if stat == \"mean\":\n",
    "            return x\n",
    "        if stat == \"median\":\n",
    "            return x\n",
    "        if stat == \"logmean\":\n",
    "            return np.log(x + eps)\n",
    "        raise ValueError(\"stat must be 'mean', 'median', or 'logmean'\")\n",
    "\n",
    "    pooled_t = transform(pooled)\n",
    "\n",
    "    def T(a_idx_mask):\n",
    "        A = pooled_t[a_idx_mask]\n",
    "        B = pooled_t[~a_idx_mask]\n",
    "        if stat == \"median\":\n",
    "            return np.median(A) - np.median(B)\n",
    "        else:  # mean or logmean\n",
    "            return A.mean() - B.mean()\n",
    "\n",
    "    # observed\n",
    "    obs_mask = np.zeros(N, dtype=bool)\n",
    "    obs_mask[:nA] = True\n",
    "    obs = T(obs_mask)\n",
    "\n",
    "    # permutations via random index selection (fixed nA)\n",
    "    more_extreme = 0\n",
    "    idx = np.arange(N)\n",
    "\n",
    "    for _ in range(n_perm):\n",
    "        A_idx = rng.choice(idx, size=nA, replace=False)\n",
    "        mask = np.zeros(N, dtype=bool)\n",
    "        mask[A_idx] = True\n",
    "        t = T(mask)\n",
    "\n",
    "        if alternative == \"two-sided\":\n",
    "            more_extreme += (abs(t) >= abs(obs))\n",
    "        elif alternative == \"greater\":  # species > others\n",
    "            more_extreme += (t >= obs)\n",
    "        elif alternative == \"less\":     # species < others\n",
    "            more_extreme += (t <= obs)\n",
    "        else:\n",
    "            raise ValueError(\"alternative must be 'two-sided', 'greater', or 'less'\")\n",
    "\n",
    "    p = (more_extreme + 1) / (n_perm + 1)  # avoids p=0\n",
    "    return obs, p\n",
    "\n",
    "\n",
    "mse_species = sample[\"test_reconstruction_loss\"].values\n",
    "mse_others = rest[\"test_reconstruction_loss\"].values\n",
    "\n",
    "# Example:\n",
    "obs, p = perm_test_large_imbalance(mse_species, mse_others, stat=\"mean\", alternative=\"two-sided\", n_perm=1000)\n",
    "print(\"obs:\", obs.round(6), \"p:\", p.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c126d889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "three_D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
